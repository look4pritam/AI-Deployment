# NVIDIA Triton Inference Server

### Server
- Github - [Link](https://github.com/triton-inference-server/server)
- Model Repository - [Link](https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/model_repository.html)
- Model Configuration - [Link](https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/model_configuration.html)
- Secure Deployment - [Link](https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/customization_guide/deploy.html)

### Client
- Github - [Link](https://github.com/triton-inference-server/client)
- Protocols
  - HTTP
  - gRPC
- Languages
  - C++
  - Python
  - JAVA

### Deploy HuggingFace Models
- Github - [Link](https://github.com/triton-inference-server/tutorials/tree/main/HuggingFace)
